{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9eb4b4d47333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "#importing libs\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Using any functions/packages you want, join these two data sets by “date” and “source_id”, returning\n",
    "#all rows from both regardless of whether there is a match between the two data sets.\n",
    "icost = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_cost.csv\")\n",
    "irev = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_Rev.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icost_irev = pd.merge(icost, irev, how='outer', on=[\"date\", \"source_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Using any functions/packages you want, join these two data sets by “date” and “source_id”, returning\n",
    "#only the rows from the “Cost” file that have no corresponding date in the “Revenue” file.\n",
    "\n",
    "icost_irev[pd.isnull(icost_irev[\"revenue\"]) & pd.notnull(icost_irev[\"cost\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3)Using your result from #1, what are the Top 4 sources (“source_id” values) in terms of total revenue\n",
    "# generation across this data set? How would you visualize the monthly revenue for those Top 4 sources?\n",
    "# (note: you don’t need to actually create a plot; you can just describe what your ideal visual would look\n",
    "# like)\n",
    "\n",
    "icost_irev.groupby(['source_id'])['revenue'].sum().sort_values(ascending = False).head(4)\n",
    "\n",
    "top4_sources = icost_irev.groupby(['source_id']).agg(revenue_sum =('revenue','sum')).sort_values(by='revenue_sum', ascending = False).head(4)\n",
    "\n",
    "top4_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('A simple bar chart over months would be one way to visualize.\\nOther way would be a trend line i.e 4 trend line of sources across the months.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7d34e321ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0micost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_Activity.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdummy_genders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdummy_metro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metropolitan_area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'metro_area'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "#Questions 4 and 5 deal with “InterviewData_Activity.csv”.\n",
    "#(4) Assuming you’ve read the data into a Pandas DataFrame called df, run the following code to build a basic logistic regression model. Apply this model to the same data that the model was trained on and assess the prediction accuracy.\n",
    "#(5) Split the data into training and test samples, and build a model over the training data using the following Python code. Assess the training data model’s accuracy on the test data. Why does the accuracy change so much?\n",
    "\n",
    "icost = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_Activity.csv\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "dummy_genders = pd.get_dummies(df['gender'], prefix = 'gender')\n",
    "dummy_metro = pd.get_dummies(df['metropolitan_area'], prefix = 'metro_area')\n",
    "dummy_device = pd.get_dummies(df['device_type'], prefix = 'device')\n",
    "cols_to_keep = ['active', 'age']\n",
    "activity_data = df[cols_to_keep].join(dummy_genders.ix[:, 'gender_M':])\n",
    "activity_data = activity_data.join(dummy_metro.ix[:, 'metro_area_Birmingham':])\n",
    "activity_data = activity_data.join(dummy_device.ix[:, 'device_Mobile':])\n",
    "activity_data = sm.add_constant(activity_data, prepend=False)\n",
    "explanatory_cols = activity_data.columns[1:]\n",
    "full_logit_model = sm.GLM(activity_data['active'],\n",
    "                          activity_data[explanatory_cols],\n",
    "                          family=sm.families.Binomial())\n",
    "result = full_logit_model.fit()\n",
    "\n",
    "\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
