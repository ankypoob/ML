{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libs\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Using any functions/packages you want, join these two data sets by “date” and “source_id”, returning\n",
    "#all rows from both regardless of whether there is a match between the two data sets.\n",
    "icost = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_cost.csv\")\n",
    "irev = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_Rev.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "icost_irev = pd.merge(icost, irev, how='outer', on=[\"date\", \"source_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>PA0923</td>\n",
       "      <td>5586.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12/17/14</td>\n",
       "      <td>PA0952</td>\n",
       "      <td>6662.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5/22/14</td>\n",
       "      <td>PA0411</td>\n",
       "      <td>4795.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/14/14</td>\n",
       "      <td>PA0168</td>\n",
       "      <td>9651.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2/13/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11/23/14</td>\n",
       "      <td>PA0277</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11/27/14</td>\n",
       "      <td>PA0057</td>\n",
       "      <td>7423.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3/29/14</td>\n",
       "      <td>PA0552</td>\n",
       "      <td>7894.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4/3/14</td>\n",
       "      <td>PA0619</td>\n",
       "      <td>4288.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8/21/14</td>\n",
       "      <td>PA0552</td>\n",
       "      <td>4653.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12/19/14</td>\n",
       "      <td>PA0258</td>\n",
       "      <td>8300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11/13/14</td>\n",
       "      <td>PA0830</td>\n",
       "      <td>5474.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4/25/14</td>\n",
       "      <td>PA0752</td>\n",
       "      <td>3043.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>PA0859</td>\n",
       "      <td>9934.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10/18/14</td>\n",
       "      <td>PA0752</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3/10/14</td>\n",
       "      <td>PA0792</td>\n",
       "      <td>5460.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5/20/14</td>\n",
       "      <td>PA0577</td>\n",
       "      <td>9377.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10/7/14</td>\n",
       "      <td>PA0270</td>\n",
       "      <td>7632.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>12/23/14</td>\n",
       "      <td>PA0732</td>\n",
       "      <td>9032.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4/26/14</td>\n",
       "      <td>PA0318</td>\n",
       "      <td>9037.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10/19/14</td>\n",
       "      <td>PA0277</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4/5/14</td>\n",
       "      <td>PA0198</td>\n",
       "      <td>5659.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7/19/14</td>\n",
       "      <td>PA0368</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6/24/14</td>\n",
       "      <td>PA0843</td>\n",
       "      <td>5787.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7/24/14</td>\n",
       "      <td>PA0873</td>\n",
       "      <td>6404.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>12/4/14</td>\n",
       "      <td>PA0318</td>\n",
       "      <td>841.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7/17/14</td>\n",
       "      <td>PA0368</td>\n",
       "      <td>8858.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3/23/14</td>\n",
       "      <td>PA0808</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7/17/14</td>\n",
       "      <td>PA0923</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8/5/14</td>\n",
       "      <td>PA0368</td>\n",
       "      <td>8027.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>4/5/14</td>\n",
       "      <td>PA0169</td>\n",
       "      <td>4103.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>4/13/14</td>\n",
       "      <td>PA0830</td>\n",
       "      <td>3416.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9/23/14</td>\n",
       "      <td>PA0174</td>\n",
       "      <td>9380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9945</th>\n",
       "      <td>2/21/14</td>\n",
       "      <td>PA0900</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>1/8/14</td>\n",
       "      <td>PA0057</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>5/8/14</td>\n",
       "      <td>PA0696</td>\n",
       "      <td>9927.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>3/10/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>5846.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>4/5/14</td>\n",
       "      <td>PA0352</td>\n",
       "      <td>8305.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>8/14/14</td>\n",
       "      <td>PA0270</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9954</th>\n",
       "      <td>10/17/14</td>\n",
       "      <td>PA0474</td>\n",
       "      <td>7476.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>8/16/14</td>\n",
       "      <td>PA0126</td>\n",
       "      <td>5456.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>5/10/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>9868.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>12/3/14</td>\n",
       "      <td>PA0534</td>\n",
       "      <td>454.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>3/22/14</td>\n",
       "      <td>PA0607</td>\n",
       "      <td>4871.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>11/29/14</td>\n",
       "      <td>PA0352</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>7/22/14</td>\n",
       "      <td>PA0394</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>12/23/14</td>\n",
       "      <td>PA0198</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>10/16/14</td>\n",
       "      <td>PA0534</td>\n",
       "      <td>8053.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>11/25/14</td>\n",
       "      <td>PA0411</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>3/11/14</td>\n",
       "      <td>PA0168</td>\n",
       "      <td>9353.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>10/25/14</td>\n",
       "      <td>PA0751</td>\n",
       "      <td>5195.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>12/8/14</td>\n",
       "      <td>PA0752</td>\n",
       "      <td>788.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>9/14/14</td>\n",
       "      <td>PA0526</td>\n",
       "      <td>6959.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>6/8/14</td>\n",
       "      <td>PA0752</td>\n",
       "      <td>3574.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>7/4/14</td>\n",
       "      <td>PA0751</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>12/7/14</td>\n",
       "      <td>PA0900</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>7/11/14</td>\n",
       "      <td>PA0474</td>\n",
       "      <td>726.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1/10/14</td>\n",
       "      <td>PA0830</td>\n",
       "      <td>6202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1/31/14</td>\n",
       "      <td>PA0467</td>\n",
       "      <td>7057.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10/1/14</td>\n",
       "      <td>PA0293</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4609 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date source_id    cost  revenue\n",
       "4     11/30/14    PA0923  5586.0      NaN\n",
       "6     12/17/14    PA0952  6662.0      NaN\n",
       "7      5/22/14    PA0411  4795.0      NaN\n",
       "9     10/14/14    PA0168  9651.0      NaN\n",
       "10     2/13/14    PA0354  2752.0      NaN\n",
       "12    11/23/14    PA0277  5691.0      NaN\n",
       "13    11/27/14    PA0057  7423.0      NaN\n",
       "16     3/29/14    PA0552  7894.0      NaN\n",
       "20      4/3/14    PA0619  4288.0      NaN\n",
       "22     8/21/14    PA0552  4653.0      NaN\n",
       "25    12/19/14    PA0258  8300.0      NaN\n",
       "29    11/13/14    PA0830  5474.0      NaN\n",
       "30     4/25/14    PA0752  3043.0      NaN\n",
       "31    11/30/14    PA0859  9934.0      NaN\n",
       "33    10/18/14    PA0752  1141.0      NaN\n",
       "36     3/10/14    PA0792  5460.0      NaN\n",
       "37     5/20/14    PA0577  9377.0      NaN\n",
       "39     10/7/14    PA0270  7632.0      NaN\n",
       "40    12/23/14    PA0732  9032.0      NaN\n",
       "41     4/26/14    PA0318  9037.0      NaN\n",
       "44    10/19/14    PA0277  3052.0      NaN\n",
       "45      4/5/14    PA0198  5659.0      NaN\n",
       "48     7/19/14    PA0368  8149.0      NaN\n",
       "49     6/24/14    PA0843  5787.0      NaN\n",
       "50     7/24/14    PA0873  6404.0      NaN\n",
       "53     12/4/14    PA0318   841.0      NaN\n",
       "55     7/17/14    PA0368  8858.0      NaN\n",
       "57     3/23/14    PA0808  3381.0      NaN\n",
       "62     7/17/14    PA0923  6689.0      NaN\n",
       "63      8/5/14    PA0368  8027.0      NaN\n",
       "...        ...       ...     ...      ...\n",
       "9937    4/5/14    PA0169  4103.0      NaN\n",
       "9942   4/13/14    PA0830  3416.0      NaN\n",
       "9944   9/23/14    PA0174  9380.0      NaN\n",
       "9945   2/21/14    PA0900  3004.0      NaN\n",
       "9946    1/8/14    PA0057  2308.0      NaN\n",
       "9947    5/8/14    PA0696  9927.0      NaN\n",
       "9950   3/10/14    PA0354  5846.0      NaN\n",
       "9952    4/5/14    PA0352  8305.0      NaN\n",
       "9953   8/14/14    PA0270  5684.0      NaN\n",
       "9954  10/17/14    PA0474  7476.0      NaN\n",
       "9956   8/16/14    PA0126  5456.0      NaN\n",
       "9957   5/10/14    PA0354  9868.0      NaN\n",
       "9962   12/3/14    PA0534   454.0      NaN\n",
       "9967   3/22/14    PA0607  4871.0      NaN\n",
       "9970  11/29/14    PA0352   550.0      NaN\n",
       "9972   7/22/14    PA0394  3873.0      NaN\n",
       "9973  12/23/14    PA0198  1795.0      NaN\n",
       "9974  10/16/14    PA0534  8053.0      NaN\n",
       "9977  11/25/14    PA0411  3781.0      NaN\n",
       "9978   3/11/14    PA0168  9353.0      NaN\n",
       "9981  10/25/14    PA0751  5195.0      NaN\n",
       "9984   12/8/14    PA0752   788.0      NaN\n",
       "9986   9/14/14    PA0526  6959.0      NaN\n",
       "9991    6/8/14    PA0752  3574.0      NaN\n",
       "9992    7/4/14    PA0751  2320.0      NaN\n",
       "9993   12/7/14    PA0900  2037.0      NaN\n",
       "9994   7/11/14    PA0474   726.0      NaN\n",
       "9995   1/10/14    PA0830  6202.0      NaN\n",
       "9996   1/31/14    PA0467  7057.0      NaN\n",
       "9998   10/1/14    PA0293  1053.0      NaN\n",
       "\n",
       "[4609 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2) Using any functions/packages you want, join these two data sets by “date” and “source_id”, returning\n",
    "#only the rows from the “Cost” file that have no corresponding date in the “Revenue” file.\n",
    "\n",
    "icost_irev[pd.isnull(icost_irev[\"revenue\"]) & pd.notnull(icost_irev[\"cost\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id\n",
       "PA0527    1385747.0\n",
       "PA0308    1338615.0\n",
       "PA0352    1309685.0\n",
       "PA0552    1283190.0\n",
       "Name: revenue, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)Using your result from #1, what are the Top 4 sources (“source_id” values) in terms of total revenue\n",
    "# generation across this data set? How would you visualize the monthly revenue for those Top 4 sources?\n",
    "# (note: you don’t need to actually create a plot; you can just describe what your ideal visual would look\n",
    "# like)\n",
    "\n",
    "icost_irev = icost_irev.groupby(['source_id'])['revenue'].sum().sort_values(ascending = False).head(4)\n",
    "\n",
    "#top4_sources = icost_irev.groupby(['source_id']).agg(revenue_sum =('revenue','sum')).sort_values(by='revenue_sum', ascending = False).head(4)\n",
    "\n",
    "icost_irev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple bar chart over months would be one way to visualize.\n",
      "Other way would be a trend line i.e 4 trend line of sources across the months.\n"
     ]
    }
   ],
   "source": [
    "print('A simple bar chart over months would be one way to visualize.\\nOther way would be a trend line i.e 4 trend line of sources across the months.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  del sys.path[0]\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "//anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>active</td>      <th>  No. Observations:  </th>  <td>  5420</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  5408</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -3613.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 29 May 2020</td> <th>  Deviance:          </th> <td>  7226.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:21:16</td>     <th>  Pearson chi2:      </th> <td>5.38e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>22</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                   <td>    0.0136</td> <td>    0.003</td> <td>    5.180</td> <td> 0.000</td> <td>    0.008</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_M</th>              <td>   -0.6103</td> <td>    0.083</td> <td>   -7.343</td> <td> 0.000</td> <td>   -0.773</td> <td>   -0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Birmingham</th> <td>   -0.0547</td> <td>    0.095</td> <td>   -0.576</td> <td> 0.564</td> <td>   -0.241</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Charlotte</th>  <td>   -1.8619</td> <td>    0.337</td> <td>   -5.529</td> <td> 0.000</td> <td>   -2.522</td> <td>   -1.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Detroit</th>    <td>   -0.0792</td> <td>    0.115</td> <td>   -0.689</td> <td> 0.491</td> <td>   -0.304</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Houston</th>    <td>   -0.4496</td> <td>    0.093</td> <td>   -4.850</td> <td> 0.000</td> <td>   -0.631</td> <td>   -0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Mobile</th>     <td>   -1.7244</td> <td>    0.259</td> <td>   -6.655</td> <td> 0.000</td> <td>   -2.232</td> <td>   -1.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Nashville</th>  <td>   22.4506</td> <td> 1.35e+04</td> <td>    0.002</td> <td> 0.999</td> <td>-2.64e+04</td> <td> 2.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>metro_area_Tampa</th>      <td>    0.1370</td> <td>    0.104</td> <td>    1.312</td> <td> 0.189</td> <td>   -0.068</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>device_Mobile</th>         <td>   -1.5004</td> <td>    0.264</td> <td>   -5.685</td> <td> 0.000</td> <td>   -2.018</td> <td>   -0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>device_Tablet</th>         <td>   -1.2342</td> <td>    0.269</td> <td>   -4.585</td> <td> 0.000</td> <td>   -1.762</td> <td>   -0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>    1.1553</td> <td>    0.290</td> <td>    3.991</td> <td> 0.000</td> <td>    0.588</td> <td>    1.723</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                 active   No. Observations:                 5420\n",
       "Model:                            GLM   Df Residuals:                     5408\n",
       "Model Family:                Binomial   Df Model:                           11\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -3613.1\n",
       "Date:                Fri, 29 May 2020   Deviance:                       7226.3\n",
       "Time:                        12:21:16   Pearson chi2:                 5.38e+03\n",
       "No. Iterations:                    22                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "age                       0.0136      0.003      5.180      0.000       0.008       0.019\n",
       "gender_M                 -0.6103      0.083     -7.343      0.000      -0.773      -0.447\n",
       "metro_area_Birmingham    -0.0547      0.095     -0.576      0.564      -0.241       0.131\n",
       "metro_area_Charlotte     -1.8619      0.337     -5.529      0.000      -2.522      -1.202\n",
       "metro_area_Detroit       -0.0792      0.115     -0.689      0.491      -0.304       0.146\n",
       "metro_area_Houston       -0.4496      0.093     -4.850      0.000      -0.631      -0.268\n",
       "metro_area_Mobile        -1.7244      0.259     -6.655      0.000      -2.232      -1.217\n",
       "metro_area_Nashville     22.4506   1.35e+04      0.002      0.999   -2.64e+04    2.64e+04\n",
       "metro_area_Tampa          0.1370      0.104      1.312      0.189      -0.068       0.342\n",
       "device_Mobile            -1.5004      0.264     -5.685      0.000      -2.018      -0.983\n",
       "device_Tablet            -1.2342      0.269     -4.585      0.000      -1.762      -0.707\n",
       "const                     1.1553      0.290      3.991      0.000       0.588       1.723\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Questions 4 and 5 deal with “InterviewData_Activity.csv”.\n",
    "#(4) Assuming you’ve read the data into a Pandas DataFrame called df, run the following code to build a basic logistic regression model. Apply this model to the same data that the model was trained on and assess the prediction accuracy.\n",
    "#(5) Split the data into training and test samples, and build a model over the training data using the following Python code. Assess the training data model’s accuracy on the test data. Why does the accuracy change so much?\n",
    "\n",
    "df = pd.read_csv(\"/Users/ankitpujari/Downloads/Shipt-DataAnalyst-TakeHome/InterviewData_Activity.csv\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "dummy_genders = pd.get_dummies(df['gender'], prefix = 'gender')\n",
    "dummy_metro = pd.get_dummies(df['metropolitan_area'], prefix = 'metro_area')\n",
    "dummy_device = pd.get_dummies(df['device_type'], prefix = 'device')\n",
    "cols_to_keep = ['active', 'age']\n",
    "activity_data = df[cols_to_keep].join(dummy_genders.ix[:, 'gender_M':])\n",
    "activity_data = activity_data.join(dummy_metro.ix[:, 'metro_area_Birmingham':])\n",
    "activity_data = activity_data.join(dummy_device.ix[:, 'device_Mobile':])\n",
    "activity_data = sm.add_constant(activity_data, prepend=False)\n",
    "explanatory_cols = activity_data.columns[1:]\n",
    "full_logit_model = sm.GLM(activity_data['active'],\n",
    "                          activity_data[explanatory_cols],\n",
    "                          family=sm.families.Binomial())\n",
    "result = full_logit_model.fit()\n",
    "\n",
    "\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "\n",
    "def confusion(y, X):\n",
    "    prediction = []\n",
    "    for number in result.predict(X).tolist():\n",
    "        if number >= .5:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "\n",
    "    print(metrics.confusion_matrix(y,prediction))\n",
    "    holder = metrics.confusion_matrix(y,prediction)\n",
    "    TP = holder[0][0]\n",
    "    TN = holder[1][1]\n",
    "    FP = holder[1][0]\n",
    "    FN = holder[0][1]\n",
    "    \n",
    "    print(\"Accuracy: \", (TP + TN) / (TP + TP + FN + FP))\n",
    "    print(\"Precision: \", (TN) / (TN + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1626 1164]\n",
      " [1109 1521]]\n",
      "('Accuracy: ', 0)\n",
      "('Precision: ', 0)\n"
     ]
    }
   ],
   "source": [
    "confusion(activity_data['active'], activity_data[explanatory_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = activity_data[1:4000]\n",
    "test_data = activity_data[4001:].copy()\n",
    "training_logit_model = sm.GLM(training_data['active'], training_data[explanatory_cols], family=sm.families.Binomial())\n",
    "\n",
    "training_result = training_logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[787 503]\n",
      " [ 53  76]]\n",
      "('Accuracy: ', 0)\n",
      "('Precision: ', 0)\n"
     ]
    }
   ],
   "source": [
    "confusion(test_data['active'], test_data[explanatory_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
